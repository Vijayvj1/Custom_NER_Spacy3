
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler

# Load the data
df = pd.read_csv('data.csv')

# Split the data into training and test sets
x_train, x_test, y_train, y_test = train_test_split(df.drop('target', axis=1), df['target'], test_size=0.25)

# Scale the features
scaler = StandardScaler()
x_train = scaler.fit_transform(x_train)
x_test = scaler.transform(x_test)

# Create the model
model = tf.keras.models.Sequential([
  tf.keras.layers.Dense(128, activation='relu'),
  tf.keras.layers.Dense(6, activation='softmax')
])

# Compile the model
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Train the model
model.fit(x_train, y_train, epochs=10)

# Evaluate the model
model.evaluate(x_test, y_test)

# Predict the classes of the test data
predictions = model.predict(x_test)

# Print the predictions
for i in range(len(predictions)):
  print('Predicted class:', predictions[i].argmax())
